---
marp: true
---

# Ch14. 업그레이드와 롤백을 이용한 업데이트 자동화

---

## 14.1 도커를 사용한 애플리케이션 업그레이드 프로세스

배포 주기는 앱 버전을 제외하고 최소한 다음 네 가지 주기를 고려해야 한다.
1. 의존 모듈의 업데이트
2. 앱 코드를 컴파일하는데 사용하는 SDK 업데이트
3. 앱이 동작하는 플랫폼의 업데이트
4. 운영체제 업데이트

빌드에 대한 신뢰감 : 성공적인 배포가 계속 되어야 쌓임
-> 이 과정의 핵심은 앱 헬스 체크

---

레플리카 모드
- mode: global
  - deploy 항목에 이 필드 설정을 추가하면 해당 서비스는 한 노드에서 한 개의 컨테이너만 실행
  - 레플리카의 수는 노드 수와 같으므로 클러스터에 새로 추가된 노드에도 컨테이너가 실행
- mode: host 
  - ports 항목에 이 필드 설정을 추가하면 해당 서비스를 인그레스 네트워크 대신 호스트의 80 포트와 연결
  - 한 노드에 레플리카 하나만으로도 무방한 가벼운 웹 앱이거나,
  - 네트워크 성능이 매우 중요해서 인그레스 네트워크 내 라우팅에 따른 오버헤드를 제거하고 싶다면 유용하게 사용 가능

---

헬스체크 설정이 들어간 이미지 v2 배포

~~~
services:
 numbers-web:
    deploy:
      mode: global
      resources:
        limits:
          cpus: "0.75"
          memory: 150M
    environment:
      RngApi__Url: http://numbers-api/rng
    healthcheck:
      interval: 20s
      retries: 3
      start_period: 30s
      timeout: 10s
~~~
서비스 업데이트는 항상 기존 컨테이너를 먼저 종료하고 새 컨테이너를 실행하는 식의 롤링 업데이트로 이루어짐

---

## 14.2 운영 환경을 위한 롤링 업데이트 설정하기

API 서비스는 좀 더 빠르고 안전하게 업데이트 해야 한다.
-> 롤링 업데이트의 세세한 방식은 컴포즈 파일 내 서비스 정의 deploy 항목에서 설정

~~~
services:
  numbers-api:
    deploy:
      replicas: 6
      resources:
        limits:
          cpus: "0.5"
          memory: 75M
      update_config:
        failure_action: rollback
        monitor: 60s
        order: start-first
        parallelism: 3
~~~

---

update_config의 항목은 다음 네 가지 프로퍼티로 이루어짐
1. parallelism : 한 번에 교체하는 레플리카의 수를 의미. 기본값은 1이므로 한 번에 레플리카가 하나씩 교체.
2. monitor : 다음 컨테이너 교체로 넘어가기 전 새로 실행한 컨테이너의 이상 여부를 모니터링 하는 시간 의미. 기본값은 0이므로 헬스 체크 설정을 포함한 이미지의 경우 이 설정값을 늘려야 함
3. failure_action : monitor에 설정한 시간 이내에 헬스 체크가 실패하거나 컨테이너가 실행 되지 않아 롤링 업데이트가 실패한 경우 어떤 조치를 취해야 하는지 의미
4. order : 레플리카를 교체하는 절차의 순서를 의미. stop-first가 기본값. 실행 중인 레플리카 수를 서비스 정의에 지정된 숫자를 넘어서지 않음. 레플리카를 실행할 수 있는 추가적인 시스템 자원이 있다면, start-first를 선택해 기존 레플리카를 제거하기 전에 새 레플리카를 먼저 검증하는 것도 좋다.

---

## 14.3 서비스 롤백 설정하기

앱을 이전 상태로 되돌리는 것은 서비스 단위로 이루어진다.

대개 롤백은 자동화된 롤링 업데이트 과정에서 새로 투입한 레플리카가 모니터링 중 오류를 일으켰을 때 수행

~~~
services:
  numbers-api:
    deploy:
      replicas: 6
      resources:
        limits:
          cpus: "0.5"
          memory: 75M
      rollback_config:
        failure_action: continue
        order: start-first
        parallelism: 6
~~~

---

업데이트 과정 정리

1. v3 v3 v3 v3 v3 v3
2. (롤링 업데이트 시작, v5 레플리카 3개 실행 됨) v3 v3 v3 v3 v3 v3 v5 v5 v5
3. (이후)
    1. (레플리카가 정상적으로 실행 됨) 업데이트 계속 v3 v3 v3 v5 v5 v5
    3. (레플리카가 정상적으로 실행 되지 않음) 1로 롤백
4. (모니터링 시간 동안 레플리카에 이상 X) v5 v5 v5 v5 v5 v5

---

## 14.4 클러스터의 중단 시간

둘 이상의 노드를 갖춘 스웜에서 실습

노드 중 한 대가 사용할 수 없게 됨
-> 이 컨테이너를 안전하게 종료시키고 다른 컨테이너로 교체하고 싶음
-> 해당 노드는 유지 보수 모드 전환. 다음 재부팅 주기 전까지 이 노드에서 컨테이너 실행 X (드레인 모드)

매니저 모드, 워커 모드 둘 다 드레인 모드 설정 가능
- 매니저 모드 : 계속 클러스터의 관리 그룹으로 가능, 클러스터 DB 동기화, 관리 API 제공, 매니저 로드 중 리더가 리더 매니저가 되는 것 가능

---

리더 매니저 : 스웜은 능동-수동 고가용성 모델을 따르기 때문에 클러스터를 실제로 통제하는 매니저는 하나. 이 매니저가 리더 매니저
- 나머지 매니저 노드는 리더 매니저가 고장나면 리더 자리를 이어 받음
- 다수결로 결정하는데, 이 때문에 매니저 노드는 항상 홀수여야 함
  - 매니저 노드를 하나 상실 -> 매니저 노드 수가 짝수 -> 워커 노드 하나를 매니저로 승격


---

발생 가능 시나리오

1. 모든 매니저가 고장
- 매니저 노드가 모두 고장을 일으켜 워커 노드만 남았다면, 앱은 그대로 잘 실행된다. 
- 인그레스 네트워크 및 서비스 레플리카는 워커 노드에서 매니저 노드 없이도 잘 동작하지만, 서비스를 모니터링 해 줄 주체가 없기 때문에 서비스 컨테이너가 이상을 일으켜도 컨테이너가 교체되지 않음
- 클러스터를 원 상태로 회복하려면 매니저 노드 복구

---

2. (리더가 아닌) 한 대를 제외한 모든 매니저 노드가 고장을 일으킨 경우
- 매니저 노드가 한 대 외에는 모두 고장, 남은 매니저 노드가 리더 매니저가 아니면 클러스터 통제권 상실 가능
- 다른 매니저 노드가 없으니 리더 매니저 승계 불가
- 해결 방법 : 남은 매니저 노드만으로 swarm init 명령에 force-new-cluster 옵션
  - 강제로 매니저 노드를 리더 매니저로 만듦
  - 그 다음 매니저 노드 추가해 고가용성 회복

---

3. 노드 간 레플리카를 고르게 재배치하기
- 서비스 레플리카는 클러스터에 노드를 추가해도 알아서 고르게 재배치 되지 않음
- 클러스터에 새로 노드를 추가해 처리 용량을 늘렸다 하더라도 서비스 업데이트 하지 않는 한, 새 노드에서는 아무 레플리카도 실행되지 않는다.
- 해결 방법 : serivice update --force 강제 서비스 업데이트 -> 노드마다 고르게 레플리카 재배치

---

## 14.5 스웜 클러스터의 고가용성

고가용성을 챙기는 방법
1. 헬스 체크 (이상 상태 빠진 컨테이너를 새 컨테이너로 교체)
2. 여러 개의 워커 노드 -> 노드 하나 고장, 다른 컨테이너 실행 능력 보존
3. 여러 개의 매니저 노드 -> 워커 노드 모니터링 + 컨테이너 배치 능력 여유분 확보

여러 지역 데이터센터 -> 하나의 클러스터
- 고가용성 확보 가능

매니저 노드 : 데이터센터 A
워커 노드 : 데이터 센터 A, B, C
- 고가용성 확보 가능
- 네트워크 지연 시간 문제 발생

-> 이를 해결하기 위해서는 클러스터를 여러 개 두어야 함