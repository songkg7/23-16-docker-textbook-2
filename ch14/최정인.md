---
marp: true
---

## 14장 업그레이드와 롤백을 이용한 업데이트 자동화
14.1 도커를 사용한 애플리케이션 업그레이드 프로세스
14.2 운영 환경을 위한 롤링 업데이트 설정하기
14.3 서비스 롤백 설정하기
14.4 클러스터의 중단 시간
14.5 스웜 클러스터의 고가용성

---

## 도커를 사용한 애플리케이션 업그레이드 프로세스

### 배포 주기를 결정하기 위해 고려해야 하는 것들
- 의존 모듈의 업데이트
- 애플리케이션 코드를 컴파일하는 데 사용하는 SDK 업데이트
- 애플리케이션이 동작하는 플랫폼의 업데이트
- 운영체제 업데이트

### 롤링 업데이트 
기존 컨테이너를 먼저 종료하고 새 컨테이너를 실행하는 방식. 즉 레플리카가 한 번에 하나씩 교체된다. 새 컨테이너가 정상적으로 실행되는지 확인이 끝난 뒤 다음 컨테이너 업데이트에 들어간다.
`global` 모드(한 노드에 레플리카를 하나만 실행)인 서비스는, 새 레플리카가 실행되기 전에 먼저 종료된다. --> 즉 서비스 중단이 짧게 발생.
`replicated` 모드인 서비스는 롤링 업데이트 방식으로 업데이트 된다.

---

### 운영환경을 위한 롤링 업데이트 설정하기
`parallelism` 한번에 교체하는 레플리카의 수  (기본값: 1)
`monitor` 다음 컨테이너 교체로 넘어가기 전에 새로 실행한 컨테이너의 이상 여부를 모니터링 하는 시간 (기본값: 0)
`failure_action` monitor에 설정한 시간 이내에 헬스체크가 실패하거나 컨테이너가 실행되지 않아 롤링 업데이트가 실패한 경우에 어떤 조치를 취해야 하는지 (기본값: 업데이트 중지) (ex. rollback) 
`order` 레플리카를 교체하는 절차의 순서 
(기본값: stop-first -- 기존 애플리케이션을 먼저 종료함으로써 실행중인 레플리카 수가 서비스 정의에 지정된 숫자를 넘지 않도록 한다.) 
(ex. start-first: 기존 레플리카를 제거하기 전에 새 레플리카를 먼저 검증)

---

### 서비스 롤백 설정하기
```
numbers-api:
    deploy:
        rollback_config:
            parallelism: 6
            monitor: 0s
            failure_action: continue
            order: start-first
```
적극적인 롤백 전략을 위한 설정 예시.

`유의` 배포 이후에도 업데이트/롤백 설정을 포함해야 함. 그렇지 않으면 업데이트 설정이 기본값으로 돌아가게 된다. 롤백이 끝나고 나면 롤백 설정도 이전으로 돌아가게 된다. 

---
### 클러스터의 중단 시간
`드레인 모드` 유지보수 모드. (매니저/워커 노드 모두 드레인 모드로 설정 가능)
유지보수 모드 = 현재 실행중인 레플리카가 종료되고, 새로운 레플리카를 실행하지도 않음.
`드레인 모드인 매니저 노드` 드레인모드여도 매니저노드는 계속해서 클러스터의 관리 그룹으로 기능함. (클러스터 데이터베이스 동기화 및 관리 API 제공. 리더매니저가 되는 것도 가능함.)

### 리더 매니저
매니저 노드 중 리더. 
고가용성 확보를 위해 매니저 노드가 둘 이상 필요한데, 실질적으로 통제하는 매니저는 하나 뿐임. (도커 스웜에서. 스웜에서는 능동-수동 고가용성 모델을 따르기 때문.) 그러한 실질적인 리더를 리더 매니저라고 함. 리더 매니저가 고장나면 리더 자리를 다른 매니저 노드가 승계받음. 남은 매니저 노드 끼리 투표를 거쳐 다수결로 결정함. (그래서 매니저 노드의 수는 항상 홀수여야 함)

---

### 몇 가지 시나리오들
- 모든 매니저가 고장을 일으킨 경우
워커 노드만 남아있는 경우 - 애플리케이션은 잘 실행된다. 다만, 인그레스 네트워크/서비스 레플리카 는 매니저 노드 없이도 워커노드에서 잘 동작하지만, 서비스 컨테이너가 이상을 일으켜도 컨테이너가 교체되지 않는 일이 발생한다.
- 리더가 아닌 하나의 매니저 노드만 멀쩡하고, 나머지는 싹다 고장
남은 매니저 노드가 리더가 아니기 때문에 클러스터 통제권은 없을 수 있음. 리더 승계를 하려면 투표를 해야하는데, 얘만 살아남아서 투표도 불가능함. 즉 이런 경우를 대처하기 위해 swarm init 시 force-new-cluster 옵션을 주면, 유일한 생존자를 리더 매니저로 만들어줄 수 있음.
- 노드 간 레플리카를 고르게 재배치
클러스터에 새로 노드를 추가해서 처리 용량을 늘리더라도, 서비스를 업데이트하지 않으면 새 노드에서 아무 레플리카도 실행되지 않음. `service update --force` 명령을 주면, 노드마다 고르게 레플리카를 재배치할 수 있음

---

### 스웜 클러스터의 고가용성
여러 지역의 데이터 센터에 걸쳐서 하나의 클러스터를 구성하기 
--> 단순히 생각하면 워커노드를 서로 다른 데이터센터에 배치함으로써 고가용성을 확보할 수 있음. (클러스터 내의 노드들을 찢어놓는 방식)
But, 매니저 노드랑 다른 데이터센터에 배치된 워커노드의 경우, 클러스터 간 네트워크 지연이 발생할 경우 문제가 됨. 매니저 노드는 노드들이 연락 두절되었다고 판단하고, 컨테이너들을 재배치하려 들고 투표 하고 난리가 날 수 있음

즉 이러한 상황을 방지하려면, 클러스터 자체를 여러 개 구성하고, 데이터센터 마다 클러스터를 하나씩 두는 형태가 좋음. 이래야 어느 지역 전체가 장애를 겪어도 애플리케이션이 계속 동작한다.