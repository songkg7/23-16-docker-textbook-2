---
marp: true
---

## 17장 도커 이미지 최적화하기: 보안, 용량, 속도
17.1 도커 이미지를 최적화하는 법
17.2 좋은 기반 이미지를 고르는 법
17.3 이미지 레이어 수와 이미지 크기는 최소한으로
17.4 멀티 스테이지 빌드를 한 단계 업그레이드 하기
17.5 최적화가 중요한 이유

---

## 도커 이미지를 최적화 하는 법
도커는 이미지끼리 레이어를 최대한 공유하기 때문에, 이미 빌드시간/네트워크 트래픽/디스크 사용량을 아낄 수 있게 설계가 된 포맷임. 

하지만 데이터를 보수적으로 다루기 때문에(=내려받은 이미지를 명시적으로 삭제하지 않는 한 자동으로 삭제하지 않음), 디스크 용량이 쉽게 잠식될 수 있음.

```
docker system df # 이미지, 컨테이너, 볼륨, 빌드 캐시 등이 실제로 점유하는 디스크 용량 출력
docker system prune # 사용하지 않는 이미지 레이어나 빌드 캐시 비워주기
```

--- 

##  Best Practice

### `꼭 필요한 파일만 이미지에 포함시킨다`
이미지에 디렉토리를 통으로 복사한 뒤에 불필요한 파일을 별도로 삭제하더라도 의미가 없다. 불필요한 파일들은 이전 레이어에 그대로 남아있고, 다음 레이어에서 보이지 않을 뿐이다. 모든 이미지 레이어가 합쳐져서 전체 이미지가 되는 것이라서 실제로는 파일이 삭제되지 않는다.
즉, 애초에 꼭 필요한 파일만 골라서 복사해야 한다.
### `.dockerignore 에 불필요한 디렉터리나 파일 목록을 기재한다`
도커의 빌드과정 = 엔진에 빌드 컨텍스트(빌드를 실행한 디렉터리)를 압축하고 Dockerfile 스크립트를 보내면서 시작됨.
즉 빌드를 실행한 디렉터리에 불필요한 파일이 포함되어 있으면 빌드 컨텍스트 용량도 커지고 전송 시간도 커진다.

---

## 좋은 기반 이미지를 고르는 법
이미지의 용량이 작을수록, 디스크 용량을 덜 차지하고 네트워크 전송시간이 줄어든다는 것 뿐만 아니라, 보안 상 허점을 덜 제공한다는 이점도 있다.
(ex) curl이 설치된 이미지는 악의적 공격에 노출되기 쉬움. 자바 SDK가 들어있는 이미지에의 경우, 누군가 컨테이너 내에서 악의적 코드를 작성하고 이를 컴파일하여 악의적 행동을 할 수 있음.

즉, 기반 이미지는 애플리케이션 실행에 필요한 모든 것을 갖춰야 하지만, 빌드에 필요한 도구를 포함시켜서는 안된다.

### Best Practice
- 골든 이미지를 기반으로 하기 
- 이미지 분석 도구(ex. 앤코어)를 이미지에 삽입하여, 빌드 중에 보안 검사를 수행하기

---

## 이미지 레이어 수와 이미지 크기는 최소한으로
- 패키지 매니저의 추천 패키지를 설치하지 않는 옵션 사용하기
ex. `apt-get --no-install-recommends`

- 설치 후 패키지 목록의 캐시를 삭제하는 단계까지 하나의 RUN 인스트럭션으로 합치기
(여러 개의 RUN 인스트럭션을 하나로 합치는 것의 장점) 
이미지 레이어 수가 줄어듬
ㄴ 이 자체로는 최적화라 할 수 없지만, 최대 레이어 수 제한이 있기 때문에 신경 써야 하는 부분
ㄴ 레이어 수가 적으면 컨테이너 파일 시스템의 내용을 추적하기가 더 쉽다

- (데이터 압축/해제가 수반될 경우) 필요한 파일만 압축을 해제하고, 다운로드-압축해제-삭제 를 모두 한 단계에서 수행한다.

---

## 멀티 스테이지 빌드를 한 단계 업그레이드 하기
앞서 인스트럭션을 줄이느라 RUN 명령어들을 합치다보면, 가독성이 파괴된다.
스크립트 가독성을 높이면서도 이미지 최적화를 하는 방법 - 멀티 스테이지 빌드 잘 활용하기.

`파일다운, 압축해제, 필요한 파일만 카피` > 각 단계를 스테이지로 분리.
최종적으로 빌드된 이미지에는 이전 단계에서 명시적으로 복사해온 파일만이 포함됨. (즉 최종 빌드 이미지의 용량은 최적화된 이미지 크기와 같음.) (cf. 중간 이미지들을 사용해서 디버깅을 하기도 좋다.)

```
FROM diamol/base AS download
ARG DATASET_URL = https://archive.ics.uci.deu/.../url_svmlight.tar.gz
RUN wget -0 dataset.tar.gx ${DATASET_URL}

FROM diamol/base AS expand
COPY --from=download dataset.tar.gz .
RUN tar xvzf dataset.tar.gz

FROM diamol/base
WORKDIR /dataset/url_svmlight
COPY --from=expand url_svmlight/Day1.svm .
```

---

## 멀티 스테이지 빌드를 한 단계 업그레이드 하기(cont.)

### 캐싱 활용하기 
빌드에 사용되는 설정 파일의 수정이 빈번할 경우, 설정 파일을 이미지로 복사하는 단계를 뒤에 두는 것이 좋다. 그래야 배포 파일을 내려받는 과정(보통 오래 걸림)을 캐싱할 수 있음.

> 오래 걸리는 단계는 재활용할 수 있게 앞에 두고, 수정이 잦은 파일을 취급하는 단계는 뒤에 두자.

(유의사항) 불필요한 요소들이 캐싱되지 않게끔 잘 삭제하기, 이미지에 패키지를 추가할 때는 버전 정확하게 명시하기.

---

##  Summary
### Best Practice
- 기반 이미지 잘 고르기 (자신만의 골든 이미지 갖추기)
- 멀티 스테이지 빌드 적용하기
- 불필요한 패키지/파일을 포함시키지 말고, 레이어 크기를 최소한으로 유지한다
- Dockerfile 스크립트 인스트럭션은 자주 수정하는 순서대로 뒤에 오도록 배치한다. (캐시 활용)

### 최적화가 중요한 이유
`개발 환경` - 시간, 디스크 공간을 절약하면서 더 많은 이미지를 여러 번 빌드할 수 있다.
`CI/CD 파이프라인` - 빌드시간, 검수, 푸시 시간을 절약해 파이프라인의 실행횟수를 늘릴 수 있음.
`테스트 환경` - 소스코드 다운시간, 디스크공간, 컨테이너실행시간 절약해 테스트횟수를 늘릴 수 있음.
`운영환경` - 보안 최적화, 새 서버를 준비하는 시간 줄일 수 있음
