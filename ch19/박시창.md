# 19. 도커를 이용한 로그 생성 및 관리
- 애플리케이션의 로그를 표준 출력 스트림으로 출력하면된다.

## 19.1 표준 에러 스트림과 표준 출력 스트림
- 표준출력(stdout), 표준오류(stderr) 스트림으로 출력하면된다. 해당 출력내용을 수집한다.
- 종료된 로그를 수집할 수 있도록 json 파일로도 저장한다. 해당 json 파일은 컨테이너와 동일한 생애주기를 갖는다
- `container inspect --format='{{.LogPath}}'` timecheck --> 로그 json 경로가 보입니다.
-  따로 설정하지 않으면 디스크 용량이 찰때까지 파일의 크기가 증가하니깐 롤링 설정이 필요하다
- `docker container run -d --name timcheck2 --log-opt max-size=5k --log-opt max-file=3 -e Timer__IntervalSeconds=1`

## 19.2 다른 곳으로 출력된 로그를 STDOUT 스트림에 전달하기
- 다른 곳으로 출력된 로그를 stdout 스트림에 전달
- syslog나 이벤트로그처럼(sink) 다른곳에 로그 생성하는경우 stdout으로 전달되지 못해 도커가 수집할 수 없다.
- 표준 출력으로 전달해주는 별도의 프로세스를 셸, 유틸리티로 실행하면 된다.
- 단점
    - 1. 디스크 효율
    - 2. 유틸리티 오류 안일으키게 작성 필요
    - 3. 프로세스 와 유틸리티 동기화 필요

## 19.3 컨테이너 로그 수집 및 포워딩하기
- fluentd 사용해볼 예정이다 
- FLUENTD 는 로그에 자체 메타데이터 추가 저장한다.
- FLUENTD는 전체 애플리케이션의 로그를 수집하는 역할한다.
- 보통 ELASTICSEARCH로 로그 저장하고 KIBANA로 검색한다.
- 키바나를 사용하면 특정 로그를 검색하거나 시간 기준으로 로그를 필터링 할 수있다.

## 19.4 로그 출력 및 로그 컬렉션 관리하기
- 로그는 대량의 불필요한 데이터 저장과 문제진단에 필요한 정보 확보 사이에 오가는 줄타기와 같다.
- 상세한 로그를 생산하면서 로그를 저장할떄는 필터링을 적용할 수 있어 어느 정도 도움이 된다.
- 태그의 문자열을 분리해서 애플리케이션 핵심 로그와 있으면 좋은 정도의 로그를 분리한다.
- 컴포넌트의 로그는 카프카, 사용자 로그는 일래스틱 서치, 나머지는 S3로 전송한다.

## 19.5 컨테이너의 로깅 모델
- ELASTRIC SEARCH, FLUENTD, KIBANA 스택을 사용하면서 노드들의 로그를 수집하는 것을 보여준다.
- 각 클러스터 노드마다 로그를 FLUENTD를 배치해서 수집해서 ELSASTIC SEARCH 클러스터로 전달한다.
